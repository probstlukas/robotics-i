{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f059aa9-55a0-4fe2-b66d-cf282dd7c518",
   "metadata": {},
   "source": [
    "# Robotics Toolbox Example\n",
    "Adapted based on example from https://github.com/jhavl/swift/blob/master/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5bc22e-b4e1-420b-9555-ecafeb92ee40",
   "metadata": {},
   "source": [
    "## Set up a simulation with a Franka Emika \"Panda\" robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a42e0c-77af-4344-81e0-2234703f0782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import roboticstoolbox as rtb\n",
    "import spatialmath as sm\n",
    "import numpy as np\n",
    "from swift import Swift\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66589856-1af1-41e7-ad54-756c1845ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings (change them as you like)\n",
    "\n",
    "@dataclass\n",
    "class Params:\n",
    "    # How many steps to simulate for each second. For visualization, 20 is a\n",
    "    # good trade-off.\n",
    "    simulation_frequency_in_hz: float = 20\n",
    "    # If you have sufficient screen space to arrange two tabs side-by-side,\n",
    "    # opening the simulation in a new tab (\"True\") makes it easier to see\n",
    "    # what the robot is doing after having scrolled down in the notebook.\n",
    "    open_simulation_in_new_tab: bool = False \n",
    "\n",
    "# instantiate with default values\n",
    "params = Params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52063c3b-5323-436b-904b-8226d71a34b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5 (SwiftSocket):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/daab/code/teaching/robotics-i/venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/daab/code/teaching/robotics-i/venv/lib/python3.10/site-packages/swift/SwiftRoute.py\", line 296, in __init__\n",
      "    start_server = websockets.serve(self.serve, \"localhost\", port)\n",
      "  File \"/home/daab/code/teaching/robotics-i/venv/lib/python3.10/site-packages/websockets/asyncio/server.py\", line 737, in __init__\n",
      "    self.server = Server(\n",
      "  File \"/home/daab/code/teaching/robotics-i/venv/lib/python3.10/site-packages/websockets/asyncio/server.py\", line 281, in __init__\n",
      "    self.loop = asyncio.get_running_loop()\n",
      "RuntimeError: no running event loop\n"
     ]
    }
   ],
   "source": [
    "# Create simulation with Panda robot\n",
    "env = Swift()\n",
    "env.launch(realtime=True, browser=\"notebook\" if not params.open_simulation_in_new_tab else None)\n",
    "#env.launch(realtime=True, browser=\"notebook\" if not params.open_simulation_in_new_tab else None, comms='rtc')  # Alternative Communictions\n",
    "robot = rtb.models.Panda()\n",
    "robot.q = robot.qr  # set robot joints to some default pose (here: called \"qr\" = \"joint space, ready\")\n",
    "env.add(robot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae3a9c-6168-44d9-ad82-501ebfb92705",
   "metadata": {},
   "source": [
    "You should now see a Panda robot arm in a 3D simulation (it might take a while to load)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f64ce-d289-425d-abc6-26db6e0476e1",
   "metadata": {},
   "source": [
    "## Robot State and Forward Kinematics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1c009b-66c0-409f-9a79-d89ea8b04a3a",
   "metadata": {},
   "source": [
    "To get familiar how to interact with the simulated robot, we query its current joint configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e67fa714-cb94-4d2e-a745-2ad3b425e117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.3         0.         -2.2         0.          2.\n",
      "  0.78539816]\n"
     ]
    }
   ],
   "source": [
    "joint_configuration = robot.q\n",
    "print(joint_configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b80f6-57aa-406e-a9d2-1603ff4f45e9",
   "metadata": {},
   "source": [
    "As you can see, the robot has seven joints. Now, we calculate the forward kinematics to get to know where the end effector is located in task space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d918e9a-c91f-4dd0-9d1b-02fc86ce12ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001B[38;5;1m 0.995   \u001B[0m \u001B[38;5;1m 0       \u001B[0m \u001B[38;5;1m 0.09983 \u001B[0m \u001B[38;5;4m 0.484   \u001B[0m  \u001B[0m\n",
      "  \u001B[38;5;1m 0       \u001B[0m \u001B[38;5;1m-1       \u001B[0m \u001B[38;5;1m 0       \u001B[0m \u001B[38;5;4m 0       \u001B[0m  \u001B[0m\n",
      "  \u001B[38;5;1m 0.09983 \u001B[0m \u001B[38;5;1m 0       \u001B[0m \u001B[38;5;1m-0.995   \u001B[0m \u001B[38;5;4m 0.4126  \u001B[0m  \u001B[0m\n",
      "  \u001B[38;5;244m 0       \u001B[0m \u001B[38;5;244m 0       \u001B[0m \u001B[38;5;244m 0       \u001B[0m \u001B[38;5;244m 1       \u001B[0m  \u001B[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "end_effector_pose_in_task_space = robot.fkine(joint_configuration)\n",
    "print(end_effector_pose_in_task_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ec5ef-6a5c-4294-ae89-571924b3e29a",
   "metadata": {},
   "source": [
    "The endeffector is located around 41 cm above the xy-plane. It is about 48cm away form the origin in x-direction, and 0 cm in y-direction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598b5ef8-5197-4de7-a8df-852b6d338a23",
   "metadata": {},
   "source": [
    "## Moving the Robot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bded9d-e06e-495c-ab5b-bf08322e0c37",
   "metadata": {},
   "source": [
    "We will see in a later exercise how we can control the robot, to make it reach a target pose. For the moment, we just use the following function as-is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38abe3f1-c28b-4ed1-8feb-1b49b76996e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define easy-to-use function to go to a target pose, defined in task space\n",
    "def move_end_effector_to(target_pose):\n",
    "    arrived = False\n",
    "    while not arrived:\n",
    "        task_space_vel, arrived = rtb.p_servo(robot.fkine(robot.q), target_pose, 1)\n",
    "        joint_space_vel = np.linalg.pinv(robot.jacobe(robot.q)) @ task_space_vel\n",
    "        robot.qd = joint_space_vel\n",
    "        env.step(1 / params.simulation_frequency_in_hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c82a3f0-62b5-49fc-86a2-28ca65a1da20",
   "metadata": {},
   "source": [
    "Next, we define some target poses for the end effector in task space, so that we can easily switch between them. Pose_1 is a default pose, while pose_2 is translated by (0.2, 0.2, 0.45) relative to the default pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e012b47d-59d7-4ab5-a056-37038d5aaa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pose 1:\n",
      "  \u001B[38;5;1m 0.995   \u001B[0m \u001B[38;5;1m 0       \u001B[0m \u001B[38;5;1m 0.09983 \u001B[0m \u001B[38;5;4m 0.484   \u001B[0m  \u001B[0m\n",
      "  \u001B[38;5;1m 0       \u001B[0m \u001B[38;5;1m-1       \u001B[0m \u001B[38;5;1m 0       \u001B[0m \u001B[38;5;4m 0       \u001B[0m  \u001B[0m\n",
      "  \u001B[38;5;1m 0.09983 \u001B[0m \u001B[38;5;1m 0       \u001B[0m \u001B[38;5;1m-0.995   \u001B[0m \u001B[38;5;4m 0.4126  \u001B[0m  \u001B[0m\n",
      "  \u001B[38;5;244m 0       \u001B[0m \u001B[38;5;244m 0       \u001B[0m \u001B[38;5;244m 0       \u001B[0m \u001B[38;5;244m 1       \u001B[0m  \u001B[0m\n",
      "\n",
      "Pose 2:\n",
      "  \u001B[38;5;1m 0.995   \u001B[0m \u001B[38;5;1m 0       \u001B[0m \u001B[38;5;1m 0.09983 \u001B[0m \u001B[38;5;4m 0.728   \u001B[0m  \u001B[0m\n",
      "  \u001B[38;5;1m 0       \u001B[0m \u001B[38;5;1m-1       \u001B[0m \u001B[38;5;1m 0       \u001B[0m \u001B[38;5;4m-0.2     \u001B[0m  \u001B[0m\n",
      "  \u001B[38;5;1m 0.09983 \u001B[0m \u001B[38;5;1m 0       \u001B[0m \u001B[38;5;1m-0.995   \u001B[0m \u001B[38;5;4m-0.01516 \u001B[0m  \u001B[0m\n",
      "  \u001B[38;5;244m 0       \u001B[0m \u001B[38;5;244m 0       \u001B[0m \u001B[38;5;244m 0       \u001B[0m \u001B[38;5;244m 1       \u001B[0m  \u001B[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pose_1 = robot.fkine(robot.qr)\n",
    "pose_2 = robot.fkine(robot.qr) * sm.SE3.Tx(0.2) * sm.SE3.Ty(0.2) * sm.SE3.Tz(0.45)\n",
    "print(f'Pose 1:\\n{pose_1}')\n",
    "print(f'Pose 2:\\n{pose_2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223425a0-aa09-4138-82ab-1c7514c7375a",
   "metadata": {},
   "source": [
    "Now, we can request the robot to move between these poses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42f4d4b5-8701-48d2-8e6f-ca71d8d414ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_end_effector_to(pose_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05a91ad6-94bc-405d-a95f-e243ab1d13d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_end_effector_to(pose_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eff5a3d7-0edf-49c8-b35d-44d39ef9d777",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_end_effector_to(pose_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
